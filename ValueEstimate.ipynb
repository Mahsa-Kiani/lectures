{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ValueEstimate.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Mahsa-Kiani/lectures/blob/master/ValueEstimate.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "2M3r30sXttXA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b3b739a1-d266-466d-c0c2-12e2fae0371b"
      },
      "cell_type": "code",
      "source": [
        "def estimate_home_value(size_in_sqft, number_of_bedrooms):\n",
        "\n",
        "    # Assume all homes are worth at least $50,000\n",
        "    value = 50000\n",
        "\n",
        "    # Adjust the value estimate based on the size of the house\n",
        "    value = value + (size_in_sqft * 92)\n",
        "\n",
        "    # Adjust the value estimate based on the number of bedrooms\n",
        "    value = value + (number_of_bedrooms * 10000)\n",
        "\n",
        "    return value\n",
        "\n",
        "# Estimate the value of our house:\n",
        "# - 5 bedrooms\n",
        "# - 3800 sq ft\n",
        "# Actual value: $450,000\n",
        "\n",
        "value = estimate_home_value(3800, 5)\n",
        "\n",
        "print(\"Estimated valued:\")\n",
        "print(value)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Estimated valued:\n",
            "449600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8clRua9mwQR5",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "6b401086-b0fb-42ca-90cf-abdbc4dba42d"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-483aff6e-00da-4e25-ae5a-631e39c5075f\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-483aff6e-00da-4e25-ae5a-631e39c5075f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving ml_house_data_set.csv to ml_house_data_set.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BrpIFnSMw_9r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d392d7f2-52e1-4d9a-c4b5-50e49c0b29f4"
      },
      "cell_type": "code",
      "source": [
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User uploaded file \"ml_house_data_set.csv\" with length 4560349 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "u9vr-wj4vJ68",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "911d3f97-f6cc-4e0b-d1c2-dee632ae1b85"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import webbrowser\n",
        "import os\n",
        "import io\n",
        "\n",
        "# Read the dataset into a data table using Pandas\n",
        "\n",
        "df = pd.read_csv(io.StringIO(uploaded['ml_house_data_set.csv'].decode('utf-8')))\n",
        "print(df.head())\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   year_built  stories  num_bedrooms  full_bathrooms  half_bathrooms  \\\n",
            "0        1978        1             4               1               1   \n",
            "1        1958        1             3               1               1   \n",
            "2        2002        1             3               2               0   \n",
            "3        2004        1             4               2               0   \n",
            "4        2006        1             4               2               0   \n",
            "\n",
            "   livable_sqft  total_sqft garage_type  garage_sqft  carport_sqft  \\\n",
            "0          1689        1859    attached          508             0   \n",
            "1          1984        2002    attached          462             0   \n",
            "2          1581        1578        none            0           625   \n",
            "3          1829        2277    attached          479             0   \n",
            "4          1580        1749    attached          430             0   \n",
            "\n",
            "   has_fireplace  has_pool  has_central_heating  has_central_cooling  \\\n",
            "0           True     False                 True                 True   \n",
            "1           True     False                 True                 True   \n",
            "2          False     False                 True                 True   \n",
            "3           True     False                 True                 True   \n",
            "4           True     False                 True                 True   \n",
            "\n",
            "   house_number       street_name  unit_number                city  zip_code  \\\n",
            "0         42670    Lopez Crossing          NaN            Hallfort     10907   \n",
            "1          5194      Gardner Park          NaN            Hallfort     10907   \n",
            "2          4366   Harding Islands          NaN  Lake Christinaport     11203   \n",
            "3          3302  Michelle Highway          NaN  Lake Christinaport     11203   \n",
            "4           582        Jacob Cape          NaN  Lake Christinaport     11203   \n",
            "\n",
            "   sale_price  \n",
            "0    270897.0  \n",
            "1    302404.0  \n",
            "2   2519996.0  \n",
            "3    197193.0  \n",
            "4    207897.0  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "f3iZzF_cysvX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "1e8b7e88-4526-4760-8fd7-8c9b094ba84b"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import ensemble\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "# Load the data set\n",
        "df = pd.read_csv(\"ml_house_data_set.csv\")\n",
        "\n",
        "# Remove the fields from the data set that we don't want to include in our model\n",
        "del df['house_number']\n",
        "del df['unit_number']\n",
        "del df['street_name']\n",
        "del df['zip_code']\n",
        "\n",
        "# Replace categorical data with one-hot encoded data\n",
        "features_df = pd.get_dummies(df, columns=['garage_type', 'city'])\n",
        "\n",
        "# Remove the sale price from the feature data\n",
        "del features_df['sale_price']\n",
        "\n",
        "# Create the X and y arrays\n",
        "X = features_df.as_matrix()\n",
        "y = df['sale_price'].as_matrix()\n",
        "print(X)\n",
        "print(y)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1978 1 4 ... 0 0 0]\n",
            " [1958 1 3 ... 0 0 0]\n",
            " [2002 1 3 ... 0 0 0]\n",
            " ...\n",
            " [1983 1 1 ... 0 0 0]\n",
            " [1981 1 3 ... 0 0 0]\n",
            " [1980 1 3 ... 0 0 0]]\n",
            "[ 270897.  302404. 2519996. ...   98280.   98278.  186480.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "46k3rwl9zI19",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Split the data set in a training set (70%) and a test set (30%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oQfUcvIVzSXu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9d6538c-bcf5-4500-bb7d-c9aee39207e6"
      },
      "cell_type": "code",
      "source": [
        "model = ensemble.GradientBoostingRegressor(\n",
        "    n_estimators=1000,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=6,\n",
        "    min_samples_leaf=9,\n",
        "    max_features=0.1,\n",
        "    loss='huber',\n",
        "    random_state=0\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Save the trained model to a file so we can use it in other programs\n",
        "joblib.dump(model, 'trained_house_classifier_model.pkl')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['trained_house_classifier_model.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "ILzM2w_PzXNH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7b30e7b8-745a-40b6-fccf-fb0c04eeb084"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Find the error rate on the training set\n",
        "mse = mean_absolute_error(y_train, model.predict(X_train))\n",
        "print(\"Training Set Mean Absolute Error: %.4f\" % mse)\n",
        "\n",
        "# Find the error rate on the test set\n",
        "mse = mean_absolute_error(y_test, model.predict(X_test))\n",
        "print(\"Test Set Mean Absolute Error: %.4f\" % mse)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Set Mean Absolute Error: 47130.6706\n",
            "Test Set Mean Absolute Error: 60415.2605\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S_WnDFEIzsOD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1126
        },
        "outputId": "3ddf0cca-e7fc-419d-9c63-e49708b24d87"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "# These are the feature labels from our data set\n",
        "feature_labels = np.array(['year_built', 'stories', 'num_bedrooms', 'full_bathrooms', 'half_bathrooms', 'livable_sqft', 'total_sqft', 'garage_sqft', 'carport_sqft', 'has_fireplace', 'has_pool', 'has_central_heating', 'has_central_cooling', 'garage_type_attached', 'garage_type_detached', 'garage_type_none', 'city_Amystad', 'city_Brownport', 'city_Chadstad', 'city_Clarkberg', 'city_Coletown', 'city_Davidfort', 'city_Davidtown', 'city_East Amychester', 'city_East Janiceville', 'city_East Justin', 'city_East Lucas', 'city_Fosterberg', 'city_Hallfort', 'city_Jeffreyhaven', 'city_Jenniferberg', 'city_Joshuafurt', 'city_Julieberg', 'city_Justinport', 'city_Lake Carolyn', 'city_Lake Christinaport', 'city_Lake Dariusborough', 'city_Lake Jack', 'city_Lake Jennifer', 'city_Leahview', 'city_Lewishaven', 'city_Martinezfort', 'city_Morrisport', 'city_New Michele', 'city_New Robinton', 'city_North Erinville', 'city_Port Adamtown', 'city_Port Andrealand', 'city_Port Daniel', 'city_Port Jonathanborough', 'city_Richardport', 'city_Rickytown', 'city_Scottberg', 'city_South Anthony', 'city_South Stevenfurt', 'city_Toddshire', 'city_Wendybury', 'city_West Ann', 'city_West Brittanyview', 'city_West Gerald', 'city_West Gregoryview', 'city_West Lydia', 'city_West Terrence'])\n",
        "\n",
        "# Load the trained model created with train_model.py\n",
        "model = joblib.load('trained_house_classifier_model.pkl')\n",
        "\n",
        "# Create a numpy array based on the model's feature importances\n",
        "importance = model.feature_importances_\n",
        "\n",
        "# Sort the feature labels based on the feature importance rankings from the model\n",
        "feauture_indexes_by_importance = importance.argsort()\n",
        "\n",
        "# Print each feature label, from most important to least important (reverse order)\n",
        "for index in feauture_indexes_by_importance:\n",
        "    print(\"{} - {:.2f}%\".format(feature_labels[index], (importance[index] * 100.0)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "city_Martinezfort - 0.00%\n",
            "city_Julieberg - 0.00%\n",
            "city_New Michele - 0.00%\n",
            "city_New Robinton - 0.00%\n",
            "city_Davidtown - 0.03%\n",
            "city_Rickytown - 0.08%\n",
            "city_West Terrence - 0.08%\n",
            "city_Port Daniel - 0.11%\n",
            "city_Toddshire - 0.11%\n",
            "city_Amystad - 0.11%\n",
            "city_West Brittanyview - 0.12%\n",
            "city_Fosterberg - 0.13%\n",
            "city_East Justin - 0.14%\n",
            "city_Lake Jennifer - 0.14%\n",
            "city_Jenniferberg - 0.16%\n",
            "city_Leahview - 0.16%\n",
            "city_South Stevenfurt - 0.17%\n",
            "city_Clarkberg - 0.18%\n",
            "city_Joshuafurt - 0.18%\n",
            "city_West Gerald - 0.19%\n",
            "city_Brownport - 0.19%\n",
            "city_West Lydia - 0.20%\n",
            "city_Lake Carolyn - 0.21%\n",
            "city_Port Adamtown - 0.21%\n",
            "city_Wendybury - 0.24%\n",
            "city_Port Jonathanborough - 0.26%\n",
            "city_Davidfort - 0.27%\n",
            "city_East Amychester - 0.28%\n",
            "city_Scottberg - 0.29%\n",
            "city_East Janiceville - 0.29%\n",
            "city_Lake Dariusborough - 0.29%\n",
            "city_West Gregoryview - 0.30%\n",
            "city_East Lucas - 0.32%\n",
            "city_Lake Christinaport - 0.37%\n",
            "city_Justinport - 0.38%\n",
            "city_Hallfort - 0.38%\n",
            "city_Richardport - 0.41%\n",
            "city_Morrisport - 0.49%\n",
            "city_South Anthony - 0.50%\n",
            "city_Jeffreyhaven - 0.56%\n",
            "city_North Erinville - 0.58%\n",
            "city_Lewishaven - 0.63%\n",
            "has_central_heating - 0.76%\n",
            "has_central_cooling - 0.76%\n",
            "city_Port Andrealand - 0.77%\n",
            "city_Chadstad - 0.77%\n",
            "city_West Ann - 0.80%\n",
            "city_Coletown - 0.90%\n",
            "garage_type_detached - 0.96%\n",
            "garage_type_attached - 1.03%\n",
            "city_Lake Jack - 1.13%\n",
            "garage_type_none - 1.16%\n",
            "has_pool - 1.78%\n",
            "has_fireplace - 1.79%\n",
            "half_bathrooms - 1.81%\n",
            "stories - 2.17%\n",
            "carport_sqft - 3.88%\n",
            "full_bathrooms - 3.92%\n",
            "num_bedrooms - 4.76%\n",
            "garage_sqft - 12.72%\n",
            "year_built - 14.56%\n",
            "total_sqft - 16.76%\n",
            "livable_sqft - 17.08%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "95Q93i3DFeYu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0_jIRAzq0I-C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9abb972-80bb-4921-d096-a7273e836a7c"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.externals import joblib\n",
        "\n",
        "# Load the model we trained previously\n",
        "model = joblib.load('trained_house_classifier_model.pkl')\n",
        "\n",
        "# For the house we want to value, we need to provide the features in the exact same\n",
        "# arrangement as our training data set.\n",
        "house_to_value = [\n",
        "    # House features\n",
        "    2006,   # year_built\n",
        "    1,      # stories\n",
        "    4,      # num_bedrooms\n",
        "    3,      # full_bathrooms\n",
        "    0,      # half_bathrooms \n",
        "    2200,   # livable_sqft\n",
        "    2350,   # total_sqft\n",
        "    0,      # garage_sqft\n",
        "    0,      # carport_sqft\n",
        "    True,   # has_fireplace\n",
        "    False,  # has_pool\n",
        "    True,   # has_central_heating\n",
        "    True,   # has_central_cooling\n",
        "    \n",
        "    # Garage type: Choose only one\n",
        "    0,      # attached\n",
        "    0,      # detached\n",
        "    1,      # none\n",
        "    \n",
        "    # City: Choose only one\n",
        "    0,      # Amystad\n",
        "    1,      # Brownport\n",
        "    0,      # Chadstad\n",
        "    0,      # Clarkberg\n",
        "    0,      # Coletown\n",
        "    0,      # Davidfort\n",
        "    0,      # Davidtown\n",
        "    0,      # East Amychester\n",
        "    0,      # East Janiceville\n",
        "    0,      # East Justin\n",
        "    0,      # East Lucas\n",
        "    0,      # Fosterberg\n",
        "    0,      # Hallfort\n",
        "    0,      # Jeffreyhaven\n",
        "    0,      # Jenniferberg\n",
        "    0,      # Joshuafurt\n",
        "    0,      # Julieberg\n",
        "    0,      # Justinport\n",
        "    0,      # Lake Carolyn\n",
        "    0,      # Lake Christinaport\n",
        "    0,      # Lake Dariusborough\n",
        "    0,      # Lake Jack\n",
        "    0,      # Lake Jennifer\n",
        "    0,      # Leahview\n",
        "    0,      # Lewishaven\n",
        "    0,      # Martinezfort\n",
        "    0,      # Morrisport\n",
        "    0,      # New Michele\n",
        "    0,      # New Robinton\n",
        "    0,      # North Erinville\n",
        "    0,      # Port Adamtown\n",
        "    0,      # Port Andrealand\n",
        "    0,      # Port Daniel\n",
        "    0,      # Port Jonathanborough\n",
        "    0,      # Richardport\n",
        "    0,      # Rickytown\n",
        "    0,      # Scottberg\n",
        "    0,      # South Anthony\n",
        "    0,      # South Stevenfurt\n",
        "    0,      # Toddshire\n",
        "    0,      # Wendybury\n",
        "    0,      # West Ann\n",
        "    0,      # West Brittanyview\n",
        "    0,      # West Gerald\n",
        "    0,      # West Gregoryview\n",
        "    0,      # West Lydia\n",
        "    0       # West Terrence\n",
        "]\n",
        "\n",
        "# scikit-learn assumes you want to predict the values for lots of houses at once, so it expects an array.\n",
        "# We just want to look at a single house, so it will be the only item in our array.\n",
        "homes_to_value = [\n",
        "    house_to_value\n",
        "]\n",
        "\n",
        "# Run the model and make a prediction for each house in the homes_to_value array\n",
        "predicted_home_values = model.predict(homes_to_value)\n",
        "\n",
        "# Since we are only predicting the price of one house, just look at the first prediction returned\n",
        "predicted_value = predicted_home_values[0]\n",
        "\n",
        "print(\"This house has an estimated value of ${:,.2f}\".format(predicted_value))\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This house has an estimated value of $594,639.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JuTnQ9GwHBa4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('trained_house_classifier_model.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IgxBC5iFzZg5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1100
        },
        "outputId": "e1e96cd2-4ce2-4057-dffa-a0aff13ce5ae"
      },
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "from sklearn import ensemble\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Load the data set\n",
        "df = pandas.read_csv(\"ml_house_data_set.csv\")\n",
        "\n",
        "# Remove the fields from the data set that we don't want to include in our model\n",
        "del df['house_number']\n",
        "del df['unit_number']\n",
        "del df['street_name']\n",
        "del df['zip_code']\n",
        "\n",
        "# Replace categorical data with one-hot encoded data\n",
        "features_df = pandas.get_dummies(df, columns=['garage_type', 'city'])\n",
        "del features_df['sale_price']\n",
        "\n",
        "X = features_df.as_matrix()\n",
        "y = df['sale_price'].as_matrix()\n",
        "\n",
        "# Split the data set in a training set (70%) and a test set (30%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "# Create the model\n",
        "model = ensemble.GradientBoostingRegressor()\n",
        "\n",
        "# Parameters we want to try\n",
        "#LS: Least Square errors\n",
        "# LAD: Least Absolute Deviations\n",
        "# HUBER: Huber loss function.\n",
        "param_grid = {\n",
        "    'n_estimators': [500, 1000, 3000],\n",
        "    'max_depth': [4, 6],\n",
        "    'min_samples_leaf': [3, 5, 9, 17],\n",
        "    'learning_rate': [0.1, 0.05, 0.02, 0.01],\n",
        "    'max_features': [1.0, 0.3, 0.1],\n",
        "    'loss': ['ls', 'lad', 'huber']\n",
        "}\n",
        "\n",
        "# Define the grid search we want to run. Run it with four cpus in parallel.\n",
        "gs_cv = GridSearchCV(model, param_grid, n_jobs=4)\n",
        "\n",
        "# Run the grid search - on only the training data!\n",
        "gs_cv.fit(X_train, y_train)\n",
        "\n",
        "# Print the parameters that gave us the best result!\n",
        "print(gs_cv.best_params_)\n",
        "\n",
        "# After running a .....long..... time, the output will be something like\n",
        "# {'loss': 'huber', 'learning_rate': 0.1, 'min_samples_leaf': 9, 'n_estimators': 3000, 'max_features': 0.1, 'max_depth': 6}\n",
        "\n",
        "# That is the combination that worked best.\n",
        "\n",
        "# Find the error rate on the training set using the best parameters\n",
        "mse = mean_absolute_error(y_train, gs_cv.predict(X_train))\n",
        "print(\"Training Set Mean Absolute Error: %.4f\" % mse)\n",
        "\n",
        "# Find the error rate on the test set using the best parameters\n",
        "mse = mean_absolute_error(y_test, gs_cv.predict(X_test))\n",
        "print(\"Test Set Mean Absolute Error: %.4f\" % mse)\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-a4ad6f165dc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# Run the grid search - on only the training data!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mgs_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# Print the parameters that gave us the best result!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}